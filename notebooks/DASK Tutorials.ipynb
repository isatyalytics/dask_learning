{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4235d6b",
   "metadata": {},
   "source": [
    "# DASK Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103fd88",
   "metadata": {},
   "source": [
    "Dask is a flexible library for parallel computing in Python.\n",
    "\n",
    "Dask is composed of two parts:\n",
    "\n",
    "1. Dynamic task scheduling optimized for computation. This is similar to Airflow, Luigi, Celery, or Make, but optimized for interactive computational workloads.\n",
    "\n",
    "2. “Big Data” collections like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. These parallel collections run on top of dynamic task schedulers.\n",
    "\n",
    "Dask emphasizes the following virtues:\n",
    "\n",
    "* Familiar: Provides parallelized NumPy array and Pandas DataFrame objects\n",
    "* Flexible: Provides a task scheduling interface for more custom workloads and integration with other projects.\n",
    "* Native: Enables distributed computing in pure Python with access to the PyData stack.\n",
    "* Fast: Operates with low overhead, low latency, and minimal serialization necessary for fast numerical algorithms\n",
    "* Scales up: Runs resiliently on clusters with 1000s of cores\n",
    "* Scales down: Trivial to set up and run on a laptop in a single process\n",
    "* Responsive: Designed with interactive computing in mind, it provides rapid feedback and diagnostics to aid humans\n",
    "\n",
    "Dask Collections is consists up dask array, dask dataframe, dask bag, dask delayed, dask futures. These collections help to create a task graph which can be executed by schedulers on a single machine or a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e84a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5e72e",
   "metadata": {},
   "source": [
    "#### Scales from laptops to clusters\n",
    "Dask is convenient on a laptop. It installs trivially with conda or pip and extends the size of convenient datasets from “fits in memory” to “fits on disk”.\n",
    "\n",
    "Dask can scale to a cluster of 100s of machines. It is resilient, elastic, data local, and low latency. For more information, see the documentation about the distributed scheduler.\n",
    "\n",
    "This ease of transition between single-machine to moderate cluster enables users to both start simple and grow when necessary.\n",
    "\n",
    "#### Complex Algorithms\n",
    "Dask represents parallel computations with task graphs. These directed acyclic graphs may have arbitrary structure, which enables both developers and users the freedom to build sophisticated algorithms and to handle messy situations not easily managed by the map/filter/groupby paradigm common in most data engineering frameworks.\n",
    "\n",
    "We originally needed this complexity to build complex algorithms for n-dimensional arrays but have found it to be equally valuable when dealing with messy situations in everyday problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be844cd",
   "metadata": {},
   "source": [
    "### Installing Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518e807",
   "metadata": {},
   "source": [
    "#### In Anaconda\n",
    "\n",
    "conda install dask => To install the full package from conda\n",
    "conda install dask -c conda-forge => To select a channel by using -c conda-forge\n",
    "conda install dask-core => For minimal installation of conda\n",
    "\n",
    "#### Using PIP\n",
    "python -m pip install \"dask\\[complete\\]\"    # Install everything\n",
    "python -m pip install dask                # Install only core parts of dask\n",
    "\n",
    "python -m pip install \"dask\\[array\\]\"       # Install requirements for dask array\n",
    "python -m pip install \"dask\\[dataframe\\]\"   # Install requirements for dask dataframe\n",
    "python -m pip install \"dask\\[diagnostics\\]\" # Install requirements for dask diagnostics\n",
    "python -m pip install \"dask\\[distributed\\]\" # Install requirements for distributed dask\n",
    "\n",
    "#### Installing from Source\n",
    "git clone https://github.com/dask/dask.git\n",
    "cd dask\n",
    "python -m pip install .\n",
    "\n",
    "python -m pip install \".\\[complete\\]\"\n",
    "\n",
    "python -m pip install -e . # developer install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0730a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
